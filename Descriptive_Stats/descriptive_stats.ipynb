{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e80b39c-a4e3-4b08-86b1-335f5b659039",
   "metadata": {},
   "source": [
    "# Descriptive Stats (Work in progress)\n",
    "\n",
    "By Kenneth Burchfiel\n",
    "\n",
    "Released under the MIT license\n",
    "\n",
    "Now that we've learned how to retrieve, reformat, and clean data, we can finally begin analyzing it! This notebook demonstrates how to calculate descriptive statistics in Python using the Pandas library. One benefit of performing these calculations in Python (rather than Excel, Google Sheets, or another spreadsheet program) is that, once you have these tasks scripted, you can quickly rerun these tasks whenever the original data gets updated.\\* You can even have your computer run the script on a daily or hourly basis, thus freeing up time you'd need to spend on busywork for more interesting tasks. \n",
    "\n",
    "For example, suppose leaders at NVCU would like to know, on a daily basis, how spring survey results differ from fall and winter ones. (This number could change each day as new spring survey data gets released.) One way to accomplish this task would be to retrieve survey data from your database each day; paste it into Excel or Google Sheets; pivot the data, and then share the output. However, you could also accomplish these same steps in Python. While this would likely take you longer the first time around, you could then create updated analyses of your data in mere seconds. This notebook will show you how!\n",
    "\n",
    "\\* There are certainly ways to automate Excel tasks as well (e.g. using Visual Basic). I don't have any experience with Visual Basic, so I'm not the best person to compare these two tools; however, I have no doubt that learning it would take some time, and given Python's versatility and power, I would recommend applying that time to learning Python instead. (You can get an estimate of the world's interest in Python versus Visual Basic by checking out the [TIOBE index](https://www.tiobe.com/tiobe-index/).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8841dd31-a284-4232-98f3-063e71f42f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65ac89-b778-4e44-bc1b-c879e66df038",
   "metadata": {},
   "source": [
    "We'll first import our combined set of fall, spring, and winter student survey results; these results were created within data_prep.ipynb. (Note that these results also include college and level data that we merged in from NVCU's curr_enrollment SQL table; that way, we can evaluate average results by level and college.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c6978-37d5-4a62-a505-fd37da30a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survey_results = pd.read_csv('../Data_Prep/2023_survey_results.csv')\n",
    "df_survey_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac79fc-e7e4-44c2-8719-a2439e61188d",
   "metadata": {},
   "source": [
    "## Evaluating changes in average university-wide results during the school year\n",
    "\n",
    "Our dataset contains survey results from the fall, winter, and spring. In order to determine how the mean survey score has changed over the course of the year, we can use Pandas' [`pivot_table()` function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html)--which I consider to be one of the most useful functions in the Pandas library.\n",
    "\n",
    "The pivot_table() call below introduces three key arguments:\n",
    "\n",
    "`index`: the list of values by which to group results. Although our dataset only contains data for one year, we'll still include `starting_year` in our results in order to (1) allow the function to accommodate other school years and (2) demonstrate to the viewer that all of this data comes from 2023. We'll also add both `season_order` and `season` to our list (in that order) so as to display results by season in chronological order. (Without the `season_order` argument, our results would be sorted alphabetically: by Fall, Spring, and then Winter.\n",
    "\n",
    "`values`: the metric to assess. We're interested in analyzing changes in average score by year, so we'll pass `score` as our argument.\n",
    "\n",
    "`aggfunc`: the aggregate function to apply to our list of values. We'll use `mean` here, but we could also have chosen `median` as a measure of the average.\n",
    "\n",
    "I generally like to add `reset_index()` to the result of `pivot_table` in order to remove any blank index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd3b49-6416-4af8-9c09-d15298c86248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_season = df_survey_results.pivot_table(\n",
    "    index=['starting_year', 'season_order', 'season'], \n",
    "    values='score', aggfunc='mean').reset_index()\n",
    "df_results_by_season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78ce6c-ffcc-47d5-9ea3-e412725625b3",
   "metadata": {},
   "source": [
    "These results show that the average score fell around 5 points from the fall to the winter, then increased nearly 8 points from the winter to the spring.\n",
    "\n",
    "Here's what the output looks like without the trailing reset_index() call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694fea6-963f-4956-bc2d-746d5368e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survey_results.pivot_table(\n",
    "    index=['starting_year', 'season_order', 'season'], \n",
    "    values='score', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b7671-ac8b-446c-9520-d79041fab6d6",
   "metadata": {},
   "source": [
    "We can also find the average score across seasons by setting `margins` to True. The `margins_name` argument lets us assign a name to this row; if we leave it blank, the row will be titled 'All.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e11667-143c-432d-ad3a-f5c415774ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survey_results.pivot_table(\n",
    "    index = ['starting_year', 'season_order', 'season'], \n",
    "    values = 'score', aggfunc = 'mean', margins=True, margins_name='2023 Average').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e22f3-3ce6-4dd9-aede-088bfde435b9",
   "metadata": {},
   "source": [
    "We can also use the pivot_table() function to determine survey response rates as a percentage of our current enrollment. We can import this current enrollment value from our NVCU database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13460f34-4480-4048-955c-2547817d8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = create_engine('sqlite:///../Appendix/nvcu_db.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab1beb-607c-4392-b605-da7b09476f19",
   "metadata": {},
   "source": [
    "Calculating our current enrollment by counting the number of rows in our curr_enrollment table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b75e4-25f4-4247-804a-30215897615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_count = len(pd.read_sql(\n",
    "    \"Select * from curr_enrollment\", con = e))\n",
    "enrollment_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3cf6c9-7dde-4087-949a-8e28db03300b",
   "metadata": {},
   "source": [
    "A faster way of computing this number is to request it within the original SQL query via COUNT(*). The following line, which demonstrates this approach, took only 6 milliseconds to run on my computer--one tenth the duration of the previous line (which took 62 milliseconds). If we were dealing with millions of rows instead of thousands, this performance difference would probably be even greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b066dc-c87b-4814-941e-e9d4ccbdbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_count = pd.read_sql(\n",
    "    \"Select COUNT(*) from curr_enrollment\", con = e).iloc[0]['COUNT(*)']\n",
    "enrollment_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990620d-e5ef-4ccf-a725-f910cee33dfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:40:27.826174Z",
     "iopub.status.busy": "2024-07-09T03:40:27.825182Z",
     "iopub.status.idle": "2024-07-09T03:40:27.830313Z",
     "shell.execute_reply": "2024-07-09T03:40:27.830313Z",
     "shell.execute_reply.started": "2024-07-09T03:40:27.826174Z"
    }
   },
   "source": [
    "Counting the number of survey results by season:\n",
    "\n",
    "*Note: When calculating row counts, make sure that the column you pass to the `values` argument doesn't contain null values; otherwise, your row counts will be incorrect (as null values will get excluded from your counts.) To prevent this issue, I often like to create a column that stores a value of 1 for every row. Using this column (titled `responses` in the following cell) ensures that my pivot table will show the correct row counts for each group.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9d1de-c600-4378-b1f0-2f14f7356ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survey_results['responses'] = 1\n",
    "df_response_rates = df_survey_results.pivot_table(\n",
    "    index = ['starting_year', 'season_order', 'season'], \n",
    "    values = 'responses', aggfunc = 'count').reset_index() # Because all 'count'\n",
    "# values are 1, we could have made 'sum' the aggfunc rather than 'count'\n",
    "df_response_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292cc00-1237-4b81-ad21-91a1cd9b83b4",
   "metadata": {},
   "source": [
    "Calculating response rates as the quotient of survey counts and NVCU's current enrollment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee016c34-d59e-495f-886d-0c8beaf80df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_response_rates['response_rate'] = 100*(\n",
    "    df_response_rates['responses'] / enrollment_count)\n",
    "df_response_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb7cfa3-13b9-46e9-8584-b8c335fc8de6",
   "metadata": {},
   "source": [
    "This table shows that our survey response rates were 100% during the fall and spring and around 85% during the winter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34f712-ea87-4ba6-a61e-6e854bb18d01",
   "metadata": {},
   "source": [
    "## Using the 'columns' `pivot_table()` argument to show seasons side by side\n",
    "\n",
    "Currently, the DataFrame is in 'long' format: each row shows data for one specific season. However, in order to more easily calculate the change in results from one season to another, we can also use the `columns` argument within pivot_table() in order to show scores for each season side by side. (This will prove especially useful when we add additional index variables to our pivot_table() call.\n",
    "\n",
    "The following function is similar to our earlier pivot_table calls except that the `season_order` and `season` values have been moved from the `index` argument to the argument for `columns`. This change makes the seasons appear horizontally rather than vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee84d89-9e56-4132-8bfb-e446985496dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_season_wide = df_survey_results.pivot_table(\n",
    "    index = 'starting_year', columns = ['season_order', 'season'],\n",
    "    values = 'score', aggfunc = 'mean').reset_index()\n",
    "df_results_by_season_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e131aa6f-38ec-44d8-b49b-4ebd7303e584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T01:38:03.797525Z",
     "iopub.status.busy": "2024-07-09T01:38:03.797525Z",
     "iopub.status.idle": "2024-07-09T01:38:03.802334Z",
     "shell.execute_reply": "2024-07-09T01:38:03.802334Z",
     "shell.execute_reply.started": "2024-07-09T01:38:03.797525Z"
    }
   },
   "source": [
    "Note that, because we passed two values to the `columns` parameter, two levels of headers are now visible. However, I'd like to show just one level of columns that includes the 'starting_year' value in the top row and the season names in the bottom row. We can accomplish this by first calling `to_flat_index` to 'flatten' the columns into tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0bada-2563-418d-bd80-66bd63f6bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_season_wide.columns = (\n",
    "    df_results_by_season_wide.columns.to_flat_index())\n",
    "df_results_by_season_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e57ab-1528-47f0-8a3d-593e538ef9fb",
   "metadata": {},
   "source": [
    "Next, I'll use a list comprehension to replace our tuple-based columns with string-based ones. Note that I want to keep the first entry ('starting_year') in the first tuple and the second entries (`Fall`, `Winter`, and `Spring`) in the others; this can be accomplished by adding an if/else statement to our list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98248a-c965-4181-9390-8062db64741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_season_wide.columns = [\n",
    "    column_tuple[0] if column_tuple[1] not in ['Fall', 'Winter', 'Spring'] \n",
    "    else column_tuple[1] for column_tuple in \n",
    "    df_results_by_season_wide.columns]\n",
    "df_results_by_season_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d8a02-b0fb-447d-8d68-50478720b471",
   "metadata": {},
   "source": [
    "Now that we have our seasons next to one another, we can easily calculate changes in average scores between seasons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64907c-43e2-4fae-a20b-1daf9f65bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_season_wide['Fall-Winter Change'] = (\n",
    "    df_results_by_season_wide['Winter'] - df_results_by_season_wide['Fall'])\n",
    "df_results_by_season_wide['Winter-Spring Change'] = (\n",
    "    df_results_by_season_wide['Spring'] - df_results_by_season_wide['Winter'])\n",
    "df_results_by_season_wide['Fall-Spring Change'] = (\n",
    "    df_results_by_season_wide['Spring'] - df_results_by_season_wide['Fall'])\n",
    "df_results_by_season_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c69c64-e12f-4a12-92f7-7533e34731ab",
   "metadata": {},
   "source": [
    "## Adding additional pivot index values\n",
    "\n",
    "We now know that our average NVCU student survey scores declined from the fall to the winter and then rose from the winter to the spring. Was this trend the same across colleges and levels? We can answer this question by adding our college and level fields to the `index` argument of our pivot table function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70325e22-30b0-47be-aeaa-a71c5678af10",
   "metadata": {},
   "source": [
    "In order to make this section more efficient, we can create a function that performs the pivot table, column renaming, and growth calculations shown for df_results_by_season_wide. This will greatly reduce the amount of code that we need to write to perform these additional analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823281f9-fa19-4b68-9543-f69794c75c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wide_table(index_values):\n",
    "    '''This function creates a wide pivot table of df_survey_results, then\n",
    "    performs additional column renaming steps and growth calculations.\n",
    "    \n",
    "    index_values: a list of values to pass to the index argument of \n",
    "    pivot_table().'''\n",
    "    \n",
    "    df_wide = df_survey_results.pivot_table(\n",
    "    index = index_values, columns = ['season_order', 'season'],\n",
    "    values = 'score', aggfunc = 'mean').reset_index()\n",
    "    df_wide.columns = (\n",
    "    df_wide.columns.to_flat_index())\n",
    "    df_wide.columns = [\n",
    "        column_tuple[0] if column_tuple[1] not in ['Fall', 'Winter', 'Spring'] \n",
    "        else column_tuple[1] for column_tuple in \n",
    "        df_wide.columns]\n",
    "    df_wide['Fall-Spring Change'] = (\n",
    "        df_wide['Spring'] - df_wide['Fall'])\n",
    "    df_wide['Fall-Winter Change'] = (\n",
    "        df_wide['Winter'] - df_wide['Fall'])\n",
    "    df_wide['Winter-Spring Change'] = (\n",
    "        df_wide['Spring'] - df_wide['Winter'])\n",
    "    df_wide['Fall-Spring Change'] = (\n",
    "        df_wide['Spring'] - df_wide['Fall'])\n",
    "    return df_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e28f5-585a-4a30-8580-c32c3252ef7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T02:53:55.150308Z",
     "iopub.status.busy": "2024-07-09T02:53:55.150308Z",
     "iopub.status.idle": "2024-07-09T02:53:55.153594Z",
     "shell.execute_reply": "2024-07-09T02:53:55.153594Z",
     "shell.execute_reply.started": "2024-07-09T02:53:55.150308Z"
    }
   },
   "source": [
    "### Evaluating changes in survey scores by season and college:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fb8ad-7eb2-4234-bae2-eea1f80cc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_season_and_college_wide = create_wide_table(\n",
    "    index_values = ['starting_year', 'college'])\n",
    "df_results_by_season_and_college_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c2f9f-58d8-48d6-95a9-9b3d967ae837",
   "metadata": {},
   "source": [
    "Although university-wide survey results grew from the fall to the spring, this table shows that results for two colleges (STB and STC) actually *dropped* over that time period. (Their average spring survey scores were also markedly lower than STL's and STM's.) It also demonstrates that fall-to-winter scores dropped for all colleges and that every college saw an increase in scores during the winter-to-spring period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02616ff4-24f5-4df8-9546-e210ca21d386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T02:53:55.150308Z",
     "iopub.status.busy": "2024-07-09T02:53:55.150308Z",
     "iopub.status.idle": "2024-07-09T02:53:55.153594Z",
     "shell.execute_reply": "2024-07-09T02:53:55.153594Z",
     "shell.execute_reply.started": "2024-07-09T02:53:55.150308Z"
    }
   },
   "source": [
    "### Evaluating changes in survey scores by season and level:\n",
    "\n",
    "We'll pivot the data by `level_for_sorting` and *then* `level` so as to order the rows from youngest to oldest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe12f21-0e46-48d5-bff3-e97977c52ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_by_season_and_college_wide = create_wide_table(\n",
    "    index_values = ['starting_year', 'level_for_sorting', 'level'])\n",
    "df_results_by_season_and_college_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fdfaa-c2b6-4d55-8e24-a0edc4ec5868",
   "metadata": {},
   "source": [
    "This table shows that freshmen and juniors had similar fall and spring average scores, but scores for freshmen and seniors increased. All levels showed a fall-to-winter drop followed by a winter-to-spring rise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8fc52-cca9-4078-81e9-c26742b75d79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T02:53:55.150308Z",
     "iopub.status.busy": "2024-07-09T02:53:55.150308Z",
     "iopub.status.idle": "2024-07-09T02:53:55.153594Z",
     "shell.execute_reply": "2024-07-09T02:53:55.153594Z",
     "shell.execute_reply.started": "2024-07-09T02:53:55.150308Z"
    }
   },
   "source": [
    "### Evaluating changes in survey scores by season, college, *and* level:\n",
    "\n",
    "(I originally named the following DataFrame `df_results_by_season_level_and_college_wide`, but since that's a rather long name and we'll use this DataFrame quite a bit within this section, I abbreviated the index values as 'slc'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf26a1-86b1-403b-8f7f-38f79f4fd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_slc = create_wide_table(\n",
    "    index_values = ['starting_year', 'college', 'level_for_sorting', 'level'])\n",
    "df_results_slc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b52ba-4c93-4bff-a325-7628a1503456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:05:21.906459Z",
     "iopub.status.busy": "2024-07-09T03:05:21.906459Z",
     "iopub.status.idle": "2024-07-09T03:05:21.909822Z",
     "shell.execute_reply": "2024-07-09T03:05:21.909822Z",
     "shell.execute_reply.started": "2024-07-09T03:05:21.906459Z"
    }
   },
   "source": [
    "## Comparing rows via sort_values() and rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d16b49-e961-4b8c-a0b2-03c82d24eeb2",
   "metadata": {},
   "source": [
    "Which college/level pairs had the highest and lowest spring survey results? We could examine `df_results_slc` line by line to answer this question; however, two Pandas functions--sort_values() and rank()--can make it easier to compare survey outcomes by college and level.\n",
    "\n",
    "First, here are the the five college/level pairs with the highest average spring results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24da36-d6f9-4533-adf1-3b7dbfd4078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_slc.sort_values(\n",
    "'Spring', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857cc142-4bb3-4448-a5f2-f66dbd434f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:11:35.893803Z",
     "iopub.status.busy": "2024-07-09T03:11:35.892812Z",
     "iopub.status.idle": "2024-07-09T03:11:35.897510Z",
     "shell.execute_reply": "2024-07-09T03:11:35.897510Z",
     "shell.execute_reply.started": "2024-07-09T03:11:35.893803Z"
    }
   },
   "source": [
    "And here are the five pairs with the *lowest* spring results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc2c9e-2e78-45bc-aa50-3779be9e4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_slc.sort_values(\n",
    "    'Spring', ascending = False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b877dd-5195-41d2-a203-40cadde0cb4d",
   "metadata": {},
   "source": [
    "Note that the use of sort_values() here did not actually change the underlying order of the DataFrame. Although it displays in sorted order immediately after sort_values() gets called, the DataFrame will revert to its original sort order during subsequent lines of code. The following cell demonstrates this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3734a3-3a2f-49ba-b7d8-32dcf986cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_slc.head() # Note that the DataFrame\n",
    "# is once again sorted by college and level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac66ed6-88e2-4a37-b4c9-4e376a1eb706",
   "metadata": {},
   "source": [
    "This behavior, which is seen in many other Pandas functions, is actually quite helpful: it allows you to test out changes and modifications without making them permanent (which, if you make a mistake, could force you to restart your script).\n",
    "\n",
    "It's also worth mentioning that none of these changes are affecting the underlying .csv file from which we retrieved our data. That file will only get modified if we use to_csv() to save our table to that same filename."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22941494-3f95-4c31-a4fb-85a995729e6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:23:58.641714Z",
     "iopub.status.busy": "2024-07-09T03:23:58.641714Z",
     "iopub.status.idle": "2024-07-09T03:23:58.645692Z",
     "shell.execute_reply": "2024-07-09T03:23:58.645692Z",
     "shell.execute_reply.started": "2024-07-09T03:23:58.641714Z"
    }
   },
   "source": [
    "To make a sort persistent, you can use one of the following two lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5ca67-e149-4bd3-b9ac-bf5fb8e86b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First option (my preference because it often requires fewer characters:\n",
    "df_results_slc.sort_values(\n",
    "    'Spring', inplace=True)\n",
    "\n",
    "# An alternative option (which can come in handy when making multiple\n",
    "# changes to a dataset at once):\n",
    "df_results_slc = (\n",
    "    df_results_slc.sort_values('Spring'))\n",
    "\n",
    "\n",
    "# Make sure NOT to add 'inplace = True' as an argument when using the second\n",
    "# method, as your DataFrame will be replaced with None! \n",
    "# For an explanation of None, see: \n",
    "# https://docs.python.org/3/library/constants.html#None\n",
    "\n",
    "df_results_slc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87d335-9a72-43fc-8bc2-0ca509815dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T03:24:29.465543Z",
     "iopub.status.busy": "2024-07-09T03:24:29.464540Z",
     "iopub.status.idle": "2024-07-09T03:24:29.468270Z",
     "shell.execute_reply": "2024-07-09T03:24:29.468270Z",
     "shell.execute_reply.started": "2024-07-09T03:24:29.465543Z"
    }
   },
   "source": [
    "# Calculating percentiles and ranks\n",
    "\n",
    "Ranks and percentiles are alternative ways to evaluate values relative to their peers. Let's say that the NVCU administration would like you to calculate both the rank *and* the percentile of each college/level pair's average spring score. However, they'd also like you to round the spring results to integers before making these calculations so that pairs with similar scores will get treated equally.\n",
    "\n",
    "First, we'll create a new condensed DataFrame that can store these integer-based results, ranks, and percentiles. We'll then assign ranks to each integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15afaa12-24dd-42e0-b556-5f0193f3d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a condensed DataFrame:\n",
    "df_spring_ranks = df_results_slc.copy()[[\n",
    "    'starting_year', 'college', \n",
    "    'level_for_sorting', 'level', 'Spring']].sort_values(\n",
    "    'Spring', ascending = False)\n",
    "# Converting average spring results to integers:\n",
    "df_spring_ranks['Spring'] = df_spring_ranks['Spring'].astype('int')\n",
    "\n",
    "# Calculating our ranks:\n",
    "# Note: the inclusion of \"method = 'min'\" ensures that, in the case of ties,\n",
    "# each tied row will show the lowest (i.e. best) possible rank. This is the ranking\n",
    "# convention that I'm more familiar with, but Pandas allows for other methods also.\n",
    "# ascending = False assigns the best ranks to the highest results.\n",
    "# See the df.rank() documentation for more details:\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rank.html\n",
    "\n",
    "df_spring_ranks['Spring_Rank'] = df_spring_ranks[\n",
    "'Spring'].rank(ascending = False, method = 'min')\n",
    "df_spring_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbebeb86-7c69-45f9-a60e-e9a37d0e6217",
   "metadata": {},
   "source": [
    "Our code for calculating percentiles will also use `df.rank()`; we can instruct that function to display its output as percentiles by adding the argument `pct=True`. We'll also add (1) `ascending=True` so that the highest scores will get the highest percentiles and (2) `method='max'` so that, in the case of ties, the highest possible percentile will get displayed.\n",
    "\n",
    "Note that, while the highest percentile in the following output is 100, the lowest percentile is not 0. I believe this is because Pandas calculates percentiles as the percentage of results *equal to or lower than* the current result. Therefore, even the lowest row won't get a percentile of 0 during percentile calculations, as it will at least be equal to itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0764a-b2ab-436e-bb47-a2b5dcef0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spring_ranks['Spring_Percentile'] = 100 * df_spring_ranks['Spring'].rank(\n",
    "    ascending=True, pct=True, method='max')\n",
    "df_spring_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52bf42-0575-498c-8b67-6c24d4697a60",
   "metadata": {},
   "source": [
    "Although our DataFrame was sorted by Spring results, df.rank() would still have successfully calculated ranks and percentiles regardless of how the DataFrame happened to be sorted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084ab97-64d0-4862-acbb-4f115dfd60c4",
   "metadata": {},
   "source": [
    "# More to come!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1fb8fd-cbb0-4a4b-8e88-9fd38e0fae11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
