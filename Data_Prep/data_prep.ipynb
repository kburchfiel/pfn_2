{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d535b3f-3386-484f-a319-7b1d7ee7849f",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "By Kenneth Burchfiel\n",
    "\n",
    "Released under the MIT License\n",
    "\n",
    "Before a dataset can be analyzed and visualized within Python, it often needs to be reformatted and cleaned. This script will clean and reformat our NVCU student survey results, then merge in data from a separate table in order to demonstrate how Python can easily perform these reformatting and cleaning tasks. \n",
    "\n",
    "Our survey_results database file already contains student survey responses for the fall and spring. However, let's say that you've been asked to add a set of winter results to this dataset as well, then calculate a weighted average of fall, winter, and spring survey results for each student. \n",
    "\n",
    "If these results were in the same format as the fall and spring ones and had no missing data, this process would be very simple. Unfortunately, that's not the case with the winter results that we'll be processing within this script. These results feature:\n",
    "\n",
    "1. Column names that differ from those in the fall/spring results\n",
    "2. Different data formats\n",
    "3. A missing column\n",
    "4. Duplicate values\n",
    "5. Missing values for certain students\n",
    "6. Results spread over 16 separate files (one for each school/level pair)\n",
    "\n",
    "And to make matters even more complex, these winter results are spread out over 16 different files (one for each level within each college).\n",
    "\n",
    "It would be cumbersome and mind-numbing to modify each of these 16 datasets within Excel, Google Sheets, or a similar program so that they could be combined with our pre-existing fall and spring data. However, the Python code shown below will make this data cleaning process much easier. And once this script is in place, if you happened to get next year's winter results in the same format* as this year's, you'd be able to get them cleaned up and reformatted in no time.\n",
    "\n",
    "*\\*You may find in your work, however, that the results are in yet another format the following year, followed by a different format the year after that. Data-related tasks are always made easier when inputs stay the same, but in the real world, you'll often need to rework datasets in order to make them compatible with pre-existing processes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a1087-0aa9-4b94-9f5d-b5b945ecc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db20847-a070-4368-8e80-79a0e1a57904",
   "metadata": {},
   "source": [
    "# Cleaning and reformatting winter survey data\n",
    "\n",
    "Our first step in preparing our winter survey results will be to import the 16 files that comprise them into a DataFrame. We'll first use os.listdir() to create a list of all files within our winter_results folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c249a-f33f-4553-9351-06a24dd15d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir('winter_results')\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacc8b1-c88f-4452-b71b-81b9502bb7c9",
   "metadata": {},
   "source": [
    "Next, we'll use a for loop to read each file within this list into a DataFrame. We'll then apply pd.concat() to combine these results into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda8100-de14-4f8c-b4c2-f08309799869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(f'winter_results/{file}')\n",
    "    df_list.append(df)\n",
    "df_winter_results = pd.concat(\n",
    "    [df for df in df_list]) # df for df in df_list is a list comprehension\n",
    "# that contains all DataFrames in df_list.\n",
    "df_winter_results.reset_index(drop=True,inplace=True)\n",
    "df_winter_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35d724-6f11-42c8-b0b1-94d5b7afde53",
   "metadata": {},
   "source": [
    "The following cell shows a more concise means of creating the same DataFrame. Although this approach requires fewer lines of code, it's also less flexible (as the former method allows you to make individual updates to each DataFrame if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb2cc3-e881-4749-b6ff-c520c29afaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results = pd.concat(\n",
    "    [pd.read_csv(f'winter_results/{file}') \n",
    "     for file in os.listdir('winter_results')]).reset_index(drop=True)\n",
    "df_winter_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88732b2a-04ee-4b09-9904-4be680900917",
   "metadata": {},
   "source": [
    "## Reformatting and cleaning our dataset\n",
    "\n",
    "Our next step is to combine these winter survey results with the fall and spring results in our NVCU database. Here's what those results look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9554716-2814-4bbe-b9a4-de2bb43cacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to our database:\n",
    "e = create_engine('sqlite:///../Appendix/nvcu_db.db')\n",
    "df_fall_spring_results = pd.read_sql(\n",
    "    \"Select * from survey_results\", con = e)\n",
    "df_fall_spring_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f7dce-ad54-4da4-bff2-0d8598dffdd3",
   "metadata": {},
   "source": [
    "If we naively tried to add our winter results to our fall/spring results, we'd end up with a very messy DataFrame with numerous blank cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f327daf-a091-462e-9314-94f2bab17989",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_fall_spring_results, df_winter_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac95354-ded7-4031-b6f0-5850051345b7",
   "metadata": {},
   "source": [
    "This messy output is caused by discrepancies in column names between the two tables. We'll need to rename our winter results fields to match their corresponding fields within the fall/spring table. Thankfully, Pandas makes this process very straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74374e-95e0-4f52-80bc-0c8148401fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results.rename(columns = {\n",
    "    'SEASON':'season','STARTINGYR':'starting_year',\n",
    "    'SURVEY_SCORE':'score'}, inplace = True)\n",
    "df_winter_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b71e7-8794-4354-b7d5-7bfc2f927e53",
   "metadata": {},
   "source": [
    "We'll also need to convert our `MATRIC#` and `MATRICYR` fields into a single `student_id` field. (This student_id field simply combines students' matriculation years with their matriculation numbers; see nvcu_db_gen.ipynb within the Appendix for more details.) This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ebb55-14b0-47a0-a8c3-f212f4a00ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results['MATRICYR'] += 2000 # Converts our MATRICYR\n",
    "# values from YY to YYYY format so that they'll match the format of the \n",
    "# matriculation year component of the student_id values within \n",
    "# df_fall_spring_results\n",
    "\n",
    "# Converting students' MATRICYR and MATRIC# values into student IDs:\n",
    "# (Note that both columns must be converted to strings in order for\n",
    "# this code to work.)\n",
    "df_winter_results['student_id'] = (\n",
    "    df_winter_results['MATRICYR'].astype('str') \n",
    "    + '-' \n",
    "    + df_winter_results['MATRIC#'].astype('str'))\n",
    "# Now that we've used our MATRICYR and MATRIC# columns to create \n",
    "# our student IDs, we no longer need to retain those columns:\n",
    "df_winter_results.drop(\n",
    "    ['MATRICYR', 'MATRIC#'], \n",
    "    axis = 1, inplace = True)\n",
    "df_winter_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae9587-20b9-43c1-8f9d-69fa05c7b420",
   "metadata": {},
   "source": [
    "The columns in df_winter_results now match those within df_fall_spring_results. That's great! Let's try combining the two datasets to see if we're ready to perform analyses on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f267e-6022-46cd-acab-08743fff186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat([df_fall_spring_results, \n",
    "           df_winter_results])\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525238d-0610-4a1e-beb0-b7ab47acf233",
   "metadata": {},
   "source": [
    "This output shows that, unfortunately, we're not quite ready to analyze this data just yet: there are several formatting differences that we'll need to address. \n",
    "\n",
    "For instance, the 'score' column within df_fall_spring_results uses an integer format, whereas these same numbers are formatted as strings within df_winter_results. This will produce errors when we attempt to perform numerical calculations on this field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f3ebb-c579-4968-a3c1-0b647fcc0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results['score'].mean() \n",
    "# Raises a TypeErorr: \"unsupported operand type(s) for +: 'int' and 'str'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63355c5-dfb1-453c-bbf0-c4809ca8f1e7",
   "metadata": {},
   "source": [
    "The following cell resolves this issue by converting our string-formatted score values to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1ea8a-2de4-4dda-bda5-72c6f377c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting our score values to integers:\n",
    "df_winter_results['score'] = df_winter_results[\n",
    "'score'].str.replace('.0%','').astype('int')\n",
    "df_winter_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1236504d-e348-4c4e-acd7-01b28558a7ee",
   "metadata": {},
   "source": [
    "We'll also need to reformat our winter results' `starting_year` and `season` values so that they match the formats found in the fall/spring table. \n",
    "\n",
    "The following cell replaces the 'W' values within the 'season' column with 'Winter' so that they'll match how seasons are formatted within df_fall_spring_results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3eae27-1d8f-40a2-a90d-ec199a456ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results['season'] = (\n",
    "    df_winter_results['season'].replace({'W':'Winter'}))\n",
    "df_winter_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a9028d-f56b-4a77-867a-b0b7c934f3db",
   "metadata": {},
   "source": [
    "The following code would also have worked; however, it assumes that every row within the DataFrame is indeed a winter result. This is the case in our simulated data, but in the real world, some data from other seasons might have leaked in, causing this code to incorrectly reclassify certain results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73e89c-7166-4d3e-97fc-79e5658f104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_winter_results['season'] = 'Winter'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d9a5db-b2ae-4242-9e77-0f6b72334557",
   "metadata": {},
   "source": [
    "Finally, we'll add 2000 to every starting_year value so that our years will show up within YYYY format--just as they do within our fall and spring results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec6a06-9d12-48c1-bf97-8a62c4ebf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results['starting_year'] += 2000\n",
    "df_winter_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7187b-2dd2-483e-8467-076cd926dead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T19:44:30.504588Z",
     "iopub.status.busy": "2024-07-06T19:44:30.503585Z",
     "iopub.status.idle": "2024-07-06T19:44:30.507067Z",
     "shell.execute_reply": "2024-07-06T19:44:30.507067Z",
     "shell.execute_reply.started": "2024-07-06T19:44:30.504588Z"
    }
   },
   "source": [
    "## Removing duplicates\n",
    "\n",
    "We've now successfully made our winter dataset's field names and values compatible with those in our fall/spring dataset. However, before we can combine the two together, we'll need to remove some duplicate results.\n",
    "\n",
    "The following code filters df_winter_results to include any rows whose `season`, `starting_year`, and `student_id` columns match. (The inclusion of `keep = False` instructs Pandas to return all copies of a duplicated row, not just the first one that it encounters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2374d-6de5-41a3-a6a3-4e561193e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results[df_winter_results.duplicated(\n",
    "    subset = ['season', 'starting_year', 'student_id'], \n",
    "    keep = False)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a054d-d028-45e7-9106-f3fe072df904",
   "metadata": {},
   "source": [
    "These duplicate values can easily be removed using Pandas' drop_duplicates() function. However, before removing duplicate rows, it's a good idea to consider which one to retain and then sort the DataFrame accordingly. \n",
    "\n",
    "In our case, we'll keep the duplicated row with the highest survey result and remove all others. We can do this by (1) sorting our DataFrame to show higher scores before lower ones and then (2) keeping the first row (e.g. the one with the highest score) when removing our duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb8342-4432-42d5-990d-a5648b0ba4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results.sort_values(\n",
    "    'score', ascending = False, inplace = True)\n",
    "df_winter_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328f301-bc3f-442b-8961-ea8e85fa4021",
   "metadata": {},
   "source": [
    "Removing duplicate values:\n",
    "\n",
    "Note: when removing duplicates, think carefully about which columns to include in your `subset` argument. For instance, if we had multiple years' worth of data in our table, using `['season', 'student_id']` as your subset would cause only *one* result for each student/season pair to get retained, thus removing valid data for other years from your table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497ea51-2c08-4378-8d4e-709b496b8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results.drop_duplicates(\n",
    "    subset = ['season', 'starting_year', 'student_id'], \n",
    "    keep = 'first', inplace = True)\n",
    "df_winter_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0008d262-4598-4e11-9216-fcfc82801440",
   "metadata": {},
   "source": [
    "Rerunning our duplicate check code confirms that no duplicate entries remain within our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6548cb-3953-485f-9c29-a23892d2d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_results[df_winter_results.duplicated(\n",
    "    subset = ['season', 'starting_year', 'student_id'], \n",
    "    keep = False)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8763b-27d7-4503-b639-fc49ad820f3b",
   "metadata": {},
   "source": [
    "We're now finally ready to combine df_winter_results with df_fall_spring results. However, one final issue remains with this table, however: winter survey results are missing for a number of students. This won't cause any issues with the following code, but we'll need to take these missing entries into account when analyzing our survey data within descriptive_stats.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b04e314-bfe9-4ad9-8152-4a4eaf8a1a07",
   "metadata": {},
   "source": [
    "## Combining winter survey results with our fall/spring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfe77b-fd3c-4b64-b70c-64f42e8c7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.concat(\n",
    "    [df_fall_spring_results, \n",
    "     df_winter_results]).sort_values(\n",
    "    ['starting_year', 'season']).reset_index(drop=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3c67eb-e5dc-49df-b591-a9f86ea076b2",
   "metadata": {},
   "source": [
    "We'll now save this dataset to a .csv file so that it can be processed by descriptive_stats.ipynb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05444da-d3df-458e-8b5a-98ea91d5afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('2023_survey_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0863cb-3ba4-490f-b3a0-ce51fc787405",
   "metadata": {},
   "source": [
    "This script has provided an introduction to data cleaning and reformatting. Other PFN sections will provide further examples of data reformatting, as reshaping data is often a necessary prerequisite for analysis and visualization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c9a1e-3f6e-4be9-b980-182d003a3e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
